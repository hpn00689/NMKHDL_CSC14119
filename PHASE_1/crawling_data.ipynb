{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align:center\"> **GIAI ĐOẠN 1: THU THẬP DỮ LIỆU** </p>\n",
    "---\n",
    "- **Về công cụ**: Sử dụng Selenimum và BeautifulSoup để lấy dữ liệu tự động từ website.\n",
    "- **Điều kiện tiên quyết**: Có cài đặt Chrome drivers và thư viện Selenium.\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"text-align:center\"> **I. IMPORT THƯ VIỆN CẦN THIẾT** </p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thêm những thư viện cần thiết để thực hiện việc crawling data và xử lý ở các bước sau: BeautifulSoup, Selenium, Time, Numpy, Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thư viện beautifulSoup:\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Thư viện selenium và lấy ra webdriver:\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Thư viện time để sử dụng các hàm liên quan đến thời gian\n",
    "import time\n",
    "\n",
    "# Thư viện xử lý mảng, dataframe: \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "# Thư viện tải web driver up-to-date cho máy chưa cập nhật driver\n",
    "# import chromedriver_autoinstaller\n",
    "# chromedriver_autoinstaller.install()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"text-align:center\"> **II. CÁC GIAI ĐOẠN THU THẬP DỮ LIỆU** </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mở trình duyệt Chrome ở chế độ toàn màn hình:\n",
    "browser = webdriver.Chrome()\n",
    "browser.maximize_window()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có 5 giai đoạn lấy dữ liệu lần lượt trình bày sau đây:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mở trang chủ của trang cần lấy dữ liệu, ở đây là website Premierleague.com\n",
    "browser.get('https://www.premierleague.com/players')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### <p style=\"text-align:center\"> *Giai đoạn 1: Tìm hiểu website và xử lý lần vào đầu tiên* </p>\n",
    "\n",
    "> **Một số lưu ý** khi mới bắt đầu vào website:\n",
    "- Khi mở website trên lên, mới bắt đầu vào ta sẽ thấy một bảng thông báo là phải **Accept all cookies** thì ta mới <br> có thể thực hiện tiếp trên dữ liệu.\n",
    "- Có một điểm bất cập ở đây là khi mới bắt đầu vào trang, ta phải đợi nó tải hết một số dữ liệu nên sẽ bị trễ một khoảng thời gian. <br>Với thời gian thực thi của cell tìm và click vào button accept all cookies, nó luôn luôn báo lỗi nên chúng em phải dùng phương thức <br> **time.sleep(3)** để hoãn lại 3 giây chờ web tải hoàn chỉnh rồi sau đó mới có thể nhấn vào được nút.\n",
    "- 3 giây là thời gian chúng em quan sát được để website tải được hoàn chỉnh ở môi trường lý tưởng (băng thông mạnh,...).\n",
    "\n",
    "> Lỗi trả về và cách sửa lỗi được **tham khảo**: [Stackoverflow](https://stackoverflow.com/questions/65120003/elementnotinteractableexception-using-selenium-in-python)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phương thức delay thời gian tải trang.\n",
    "time.sleep(15)   \n",
    "\n",
    "# button_Class: Kiểm tra trên website rồi lấy thủ công về.\n",
    "button_Class = '//button[@class=\"_2hTJ5th4dIYlveipSEMYHH BfdVlAo_cgSVjDUegen0F js-accept-all-close\"]'\n",
    "\n",
    "# Tìm chỗ button_class đó rồi thực hiện click vào (Accept all cookies).\n",
    "browser.find_element(By.XPATH, button_Class).click()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Kiểu tải dữ liệu của trang:**\n",
    "- Giống như Facebook hay Twitter, trang này sẽ tải gần như vô hạn khi tiếp tục kéo xuống dưới cuối.\n",
    "- Nhóm em thực hiện đoạn code liên tục kéo xuống trang dữ liệu cho đến khi nào nó tải mới, làm hoài như vậy cho đến khi trang đưa ra những dữ liệu cuối cùng."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Phạm vi lấy dữ liệu:**\n",
    "- Ở đây, nhóm em lấy dữ lệu cầu thủ ở 5 năm gần nhất để xử lý nên lấy các link ở từng năm ra đưa vào mảng url: 2022-2023, 2021-2022, 2020-2021, 2019-2020, 2018-2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mở trang chủ của trang cần lấy dữ liệu, ở đây là website Premierleague.com\n",
    "season_url = ['https://www.premierleague.com/players', \n",
    "              'https://www.premierleague.com/players?se=418&cl=-1',\n",
    "              'https://www.premierleague.com/players?se=363&cl=-1', \n",
    "              'https://www.premierleague.com/players?se=274&cl=-1', \n",
    "              'https://www.premierleague.com/players?se=210&cl=-1']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### <p style=\"text-align:center\"> *Giai đoạn 2: Kéo trang, lấy từng link cầu thủ.* </p>\n",
    "\n",
    "> **Cài đặt đoạn code kéo toàn bộ trang**: \n",
    "- Kéo trang để lấy hết đoạn html đầy đủ chứa các tag href - chứa toàn bộ link các cầu thủ.\n",
    "- Đoạn code kéo trang được tham khảo tại: [Python forum](https://python-forum.io/thread-20175.html)\n",
    "- Sử dụng song song các thư viện Selenium và thư viện BeautifulSoup để thực hiện việc lấy link dẫn đến từng cầu thủ, thực hiện xử lý trên link đó để truy cập vào dễ dàng hơn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List chứa danh sách các liên kết đến thông tin cá nhân của một cấu thủ.\n",
    "href_pos_lst = []\n",
    "\n",
    "for season in season_url:\n",
    "    browser.get(season)\n",
    "    \n",
    "    # Phương thức delay thời gian tải trang.\n",
    "    time.sleep(5)   \n",
    "    if (season_url.index(season) == 0):\n",
    "        # button_Class: Kiểm tra trên website rồi lấy thủ công về.\n",
    "        button_Class = '//button[@class=\"_2hTJ5th4dIYlveipSEMYHH BfdVlAo_cgSVjDUegen0F js-accept-all-close\"]'\n",
    "\n",
    "        # Tìm chỗ button_class đó rồi thực hiện click vào (Accept all cookies).\n",
    "        browser.find_element(By.XPATH, button_Class).click()\n",
    "\n",
    "    # Thời gian đợi cuộn tải đữ liệu\n",
    "    SCROLL_PAUSE_TIME = 20\n",
    "\n",
    "    # Lấy kích thước trang ở cuối.\n",
    "    last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "        # Cuộn đến cuối trang.\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight - 10);\")\n",
    "\n",
    "        # Cài đặt thời gian để load trang khi nó mở rộng thêm dữ liệu.\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "        # Tính toán với chiều dài cuộn mới và so sánh với chiều cao trang ban đầu.\n",
    "        new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Lấy toàn bộ source html trên trang.\n",
    "    html_text = browser.page_source\n",
    "    soup = BeautifulSoup(html_text)\n",
    "\n",
    "    # Lấy các thẻ chứa vị trí của các cầu thủ\n",
    "    player_pos = soup.find_all('td', 'hide-s')\n",
    "    player_pos = player_pos[0::2]\n",
    "\n",
    "    for i in range(len(player_pos)):\n",
    "        player_pos[i] = player_pos[i].get_text()\n",
    "\n",
    "    player_pos = np.array(player_pos)\n",
    "\n",
    "    # Lấy các thẻ chứa các đường dẫn của các cầu thủ\n",
    "    player_href = []\n",
    "    player_link = soup.find_all('a', 'playerName')\n",
    "\n",
    "    # Xử lý link để truy cập vào link nhanh chóng\n",
    "    for link in player_link: \n",
    "        raw_link = 'https:' + link.get('href')\n",
    "        true_link = raw_link.replace('overview', 'stats')\n",
    "        player_href.append(true_link)\n",
    "\n",
    "    player_href = np.array(player_href)\n",
    "\n",
    "    # Biến 2 mảng thông tin trên thành mảng 2 chiều để dễ xử lý\n",
    "    href_pos_lst_temp = np.column_stack((player_pos, player_href))\n",
    "\n",
    "    # Thêm vào mảng tổng\n",
    "    href_pos_lst.append(href_pos_lst_temp)\n",
    "\n",
    "# Đóng trang web: \n",
    "browser.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### <p style=\"text-align:center\"> *Giai đoạn 3: Sử dụng mảng link để lấy từng chỉ số cầu thủ* </p>\n",
    "> **Cài đặt đoạn code lấy chỉ số cầu thủ**:\n",
    "- Sử dụng song song các thư viện Selenium và thư viện BeautifulSoup để thực hiện việc lấy từng chỉ số cầu thủ dựa vào vị trí của họ trong mảng chứa link đã được xử lý ở trên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Làm việc trên danh sách cầu thủ: \n",
    "forward_player_data = [] \n",
    "mid_player_data = [] \n",
    "def_player_data = [] \n",
    "keeper_player_data = [] \n",
    "\n",
    "# Mở lại trình duyệt và tiến hành vào từng cầu thủ\n",
    "browser = webdriver.Chrome()\n",
    "browser.maximize_window()\n",
    "\n",
    "# Vòng lặp duyệt từng link href để vào đượt trang thống kê chỉ số từng cầu thủ.\n",
    "for season in href_pos_lst:\n",
    "    for pos, link in season:\n",
    "        browser.get(link)\n",
    "            \n",
    "        html_text = browser.page_source\n",
    "        soup = BeautifulSoup(html_text)\n",
    "        \n",
    "        # Tìm ra tất cả các thẻ như tên, các mục thống kê rồi lấy các nội dung từ đó.\n",
    "        name = soup.find('div', 'name t-colour').get_text()\n",
    "        topStat = soup.find_all('span', 'allStatContainer')\n",
    "\n",
    "        # Đưa các nội dung vào mảng một chiều như một phần tử của mảng 2 chiều toàn bộ tập dữ liệu.\n",
    "        one_player = [st.get_text().strip() for st in topStat]\n",
    "        one_player.insert(0, name)\n",
    "\n",
    "        if (pos == 'Goalkeeper'):\n",
    "            keeper_player_data.append(one_player)\n",
    "        elif (pos == 'Forward'):    \n",
    "            forward_player_data.append(one_player)\n",
    "        elif (pos == 'Midfielder'):   \n",
    "            mid_player_data.append(one_player)     \n",
    "        elif (pos == 'Defender'):   \n",
    "            def_player_data.append(one_player)\n",
    "            \n",
    "\n",
    "browser.close() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Đưa chỉ số vào DataFrame**\n",
    "- Đưa tất cả cầu thủ vào kiểu dữ liệu DataFrame của thư viện Pandas từ Python, thực hiện việc đặt tên Header dựa trên thuộc tính hiển thị trên trang web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dữ liệu các cầu thủ Forward\n",
    "dfForward = pd.DataFrame(forward_player_data)\n",
    "dfForward.columns = ['Player name', 'Appearances', 'Goals Overview', 'Wins', 'Losses', 'Goals', 'Goals per match',\n",
    "                    'Headed goals', 'Goals with right foot', 'Goals with left foot',\n",
    "                    'Penalties scored', 'Freekicks scored', 'Shots',\n",
    "                    'Shots on target', 'Shooting accuracy', 'Hit woodwork',\n",
    "                    'Big chances missed', 'Assists', 'Passes', 'Passes per match',\n",
    "                    'Big Chances Created', 'Crosses', 'Yellow cards', 'Red cards',\n",
    "                    'Fouls', 'Offsides', 'Tackles', 'Blocked shots',\n",
    "                    'Interceptions', 'Clearances', 'Headed Clearance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dữ liệu các cầu thủ midfielder\n",
    "dfMid = pd.DataFrame(mid_player_data)\n",
    "dfMid.columns = ['Player name', 'Appearances', 'Goals Overview', 'Wins', 'Losses', 'Goals', 'Goals per match',\n",
    "                    'Headed goals', 'Goals with right foot', 'Goals with left foot',\n",
    "                    'Penalties scored', 'Freekicks scored', 'Shots', 'Shots on target', \n",
    "                    'Shooting accuracy %', 'Hit woodwork', 'Big chances missed', 'Assists',\n",
    "                    'Passes', 'Passes per match', 'Big chances created', 'Crosses', 'Cross accuracy %',\n",
    "                    'Through balls', 'Accurate long balls', 'Yellow cards', 'Red cards',\n",
    "                    'Fouls', 'Offsides', 'Tackles', 'Tackle success %', 'Blocked shots',\n",
    "                    'Interceptions', 'Clearances', 'Headed clearances', 'Recoveries', 'Duels won',\n",
    "                    'Duels lost', 'Succesful 50/50s', 'Aerial battles won', 'Aerial battles lost', \n",
    "                    'Errors leading to goal']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dữ liệu các cầu thủ defender\n",
    "dfDef = pd.DataFrame(def_player_data)\n",
    "dfDef.columns = ['Player name', 'Appearances', 'Goals Overview', 'Wins', 'Losses', 'Clean sheets', \n",
    "                'Goals Conceded', 'Tackles', 'Tackle success' , 'Last man tackles',\n",
    "                'Blocked shots', 'Interceptions', 'Clearances', 'Headed Clearance',\n",
    "                'Clearances off line', 'Recoveries', 'Duels won', 'Duels lost', 'Successful 50/50s',\n",
    "                'Aerial battles won', 'Aerial battles lost', 'Own goals', 'Errors leading to goal',\n",
    "                'Assists', 'Passes', 'Passes per match', 'Big Chances Created', 'Crosses',\n",
    "                'Cross accuracy' , 'Through balls', 'Accurate long balls', 'Yellow cards',\n",
    "                'Red cards', 'Fouls', 'Offsides', 'Goals', 'Headed goals', 'Goals with right foot',\n",
    "                'Goals with left foot', 'Hit woodwork']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Xử lý bất thường dữ liệu defender**.\n",
    "\n",
    "- Có một vài ngoại lệ khi lấy dữ liệu là vài cầu thủ ở vị trí defender sẽ có định dạng khác với các cầu thủ defender còn lại, nhóm em pop nó ra khỏi dữ liệu để xử lý đưa vào DataFrame.\n",
    "- Dựa vào số cột của nó mà có thể tìm ra dòng ngoại lệ để xóa bỏ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols_att in def_player_data:\n",
    "    if len(cols_att) != 40:\n",
    "        def_player_data.pop(def_player_data.index(cols_att))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dữ liệu các keeper\n",
    "dfKeeper = pd.DataFrame(keeper_player_data)\n",
    "dfKeeper.columns = ['Player name', 'Appearances', 'Clean sheets', 'Wins', 'Losses', 'Saves',\n",
    "            'Penalties Saved', 'Punches', 'High Claims','Catches',\n",
    "            'Sweeper clearances', 'Throw outs', 'Goal Kicks',\n",
    "            'Clean sheets', 'Goals Conceded', 'Errors leading to goal',\n",
    "            'Own goals', 'Yellow cards', 'Red cards', 'Fouls', 'Goals',\n",
    "            'Assists', 'Passes', 'Passes per match', 'Accurate long balls']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### <p style=\"text-align:center\"> *Giai đoạn 4: Đưa các DataFrame đã xử lý về lại các files* </p>\n",
    "\n",
    "> **Đưa về file lưu trữ**\n",
    "- Các đoạn code Viết lại vào một file csv để tiện dùng cho sau này.\n",
    "- Xóa bỏ thuộc tính index khi viết vào file bằng thuộc tính index=False khi viết vào csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMid.to_csv('midfielder_data.csv', index=False)\n",
    "dfForward.to_csv('forward_data.csv', index=False)\n",
    "dfDef.to_csv('defender_data.csv', index=False)\n",
    "dfKeeper.to_csv('keeper_data.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "HẾT GIAI ĐOẠN 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
